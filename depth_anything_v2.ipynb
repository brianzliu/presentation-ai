{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e2c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Depth-Anything-V2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Depth Anything V2 Video Processing\n",
    "# This notebook processes video files and generates depth map videos using Depth-Anything-V2\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Set device for processing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the depth estimation pipeline\n",
    "print(\"Loading Depth-Anything-V2 model...\")\n",
    "pipe = pipeline(task=\"depth-estimation\", model=\"depth-anything/Depth-Anything-V2-Small-hf\", device=device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112be398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set up complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell if you haven't installed these packages yet\n",
    "\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "\n",
    "# Configuration\n",
    "INPUT_VIDEO_PATH = \"input_video.mp4\"\n",
    "OUTPUT_VIDEO_PATH = \"output_depth_video.mp4\"\n",
    "TEMP_FRAMES_DIR = \"temp_frames\"\n",
    "\n",
    "# Create temporary directory for frames if it doesn't exist\n",
    "if not os.path.exists(TEMP_FRAMES_DIR):\n",
    "    os.makedirs(TEMP_FRAMES_DIR)\n",
    "    \n",
    "print(\"Configuration set up complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46822912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Video Processing Functions\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"\n",
    "    Process a single frame to generate depth map\n",
    "    \n",
    "    Args:\n",
    "        frame: OpenCV frame (BGR format)\n",
    "    \n",
    "    Returns:\n",
    "        depth_frame: Processed depth map as an image\n",
    "    \"\"\"\n",
    "    # Convert BGR to RGB for PIL\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "    \n",
    "    # Generate depth map\n",
    "    depth_result = pipe(pil_image)\n",
    "    depth_map = depth_result[\"depth\"]\n",
    "    \n",
    "    return depth_map\n",
    "\n",
    "def depth_to_colormap(depth_map):\n",
    "    \"\"\"\n",
    "    Convert depth map to a colorized representation\n",
    "    \n",
    "    Args:\n",
    "        depth_map: PIL Image depth map\n",
    "    \n",
    "    Returns:\n",
    "        colorized_frame: OpenCV frame with colorized depth map\n",
    "    \"\"\"\n",
    "    # Convert depth map to numpy array\n",
    "    depth_array = np.array(depth_map)\n",
    "    \n",
    "    # Normalize depth values to 0-255 range\n",
    "    depth_normalized = ((depth_array - depth_array.min()) / \n",
    "                       (depth_array.max() - depth_array.min()) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply colormap (using matplotlib's plasma colormap)\n",
    "    colormap = cm.get_cmap('plasma')\n",
    "    depth_colored = colormap(depth_normalized / 255.0)\n",
    "    \n",
    "    # Convert to 0-255 range and remove alpha channel\n",
    "    depth_colored = (depth_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert RGB to BGR for OpenCV\n",
    "    depth_frame = cv2.cvtColor(depth_colored, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return depth_frame\n",
    "\n",
    "def get_video_properties(video_path):\n",
    "    \"\"\"\n",
    "    Get video properties like fps, width, height, and frame count\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with video properties\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    properties = {\n",
    "        'fps': int(cap.get(cv2.CAP_PROP_FPS)),\n",
    "        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "        'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    }\n",
    "    \n",
    "    cap.release()\n",
    "    return properties\n",
    "\n",
    "print(\"Video processing functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28cf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main video processing function defined!\n"
     ]
    }
   ],
   "source": [
    "# Main Video Processing Function\n",
    "\n",
    "def process_video(input_path, output_path, show_progress=True):\n",
    "    \"\"\"\n",
    "    Process entire video to generate depth map video\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input video file\n",
    "        output_path: Path to output depth map video\n",
    "        show_progress: Whether to show progress bar\n",
    "    \n",
    "    Returns:\n",
    "        success: Boolean indicating success\n",
    "    \"\"\"\n",
    "    # Check if input video exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video '{input_path}' not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    print(f\"Processing video: {input_path}\")\n",
    "    video_props = get_video_properties(input_path)\n",
    "    print(f\"Video properties: {video_props}\")\n",
    "    \n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, video_props['fps'], \n",
    "                         (video_props['width'], video_props['height']))\n",
    "    \n",
    "    # Initialize progress bar\n",
    "    frame_count = 0\n",
    "    total_frames = video_props['frame_count']\n",
    "    \n",
    "    if show_progress:\n",
    "        pbar = tqdm(total=total_frames, desc=\"Processing frames\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Read frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process frame to get depth map\n",
    "            depth_map = process_frame(frame)\n",
    "            \n",
    "            # Convert depth map to colorized representation\n",
    "            depth_frame = depth_to_colormap(depth_map)\n",
    "            \n",
    "            # Write frame to output video\n",
    "            out.write(depth_frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if show_progress:\n",
    "                pbar.update(1)\n",
    "        \n",
    "        print(f\"\\\\nProcessing complete! Processed {frame_count} frames.\")\n",
    "        print(f\"Output video saved to: {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        # Release everything\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        if show_progress:\n",
    "            pbar.close()\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"Main video processing function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ad6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization and testing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Optional: Visualization and Testing Functions\n",
    "\n",
    "def test_single_frame(video_path, frame_number=0):\n",
    "    \"\"\"\n",
    "    Test depth processing on a single frame for visualization\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        frame_number: Frame number to test (default: 0)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video '{video_path}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Open video and seek to specific frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame {frame_number}\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    # Process the frame\n",
    "    print(f\"Processing frame {frame_number}...\")\n",
    "    depth_map = process_frame(frame)\n",
    "    depth_frame = depth_to_colormap(depth_map)\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Original frame (convert BGR to RGB for matplotlib)\n",
    "    original_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(original_rgb)\n",
    "    axes[0].set_title('Original Frame')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Depth map (convert BGR to RGB for matplotlib)\n",
    "    depth_rgb = cv2.cvtColor(depth_frame, cv2.COLOR_BGR2RGB)\n",
    "    axes[1].imshow(depth_rgb)\n",
    "    axes[1].set_title('Depth Map')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"Single frame test completed!\")\n",
    "\n",
    "def display_video_info(video_path):\n",
    "    \"\"\"\n",
    "    Display information about the input video\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video '{video_path}' not found!\")\n",
    "        return\n",
    "    \n",
    "    props = get_video_properties(video_path)\n",
    "    print(f\"Video Information for: {video_path}\")\n",
    "    print(f\"  Resolution: {props['width']}x{props['height']}\")\n",
    "    print(f\"  FPS: {props['fps']}\")\n",
    "    print(f\"  Total Frames: {props['frame_count']}\")\n",
    "    print(f\"  Duration: {props['frame_count'] / props['fps']:.2f} seconds\")\n",
    "\n",
    "print(\"Visualization and testing functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fc919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VIDEO PROCESSING PIPELINE ===\\n\n",
      "Step 1: Checking input video...\n",
      "Video Information for: input_video.mp4\n",
      "  Resolution: 1620x1080\n",
      "  FPS: 30\n",
      "  Total Frames: 317\n",
      "  Duration: 10.57 seconds\n",
      "\\nStep 3: Processing entire video...\n",
      "This may take a while depending on video length and hardware...\n",
      "Processing video: input_video.mp4\n",
      "Video properties: {'fps': 30, 'width': 1620, 'height': 1080, 'frame_count': 317}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/317 [00:00<?, ?it/s]/tmp/ipykernel_15047/1460357124.py:43: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap = cm.get_cmap('plasma')\n",
      "Processing frames:   3%|▎         | 10/317 [00:03<00:53,  5.70it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing frames: 100%|██████████| 317/317 [00:48<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing complete! Processed 317 frames.\n",
      "Output video saved to: output_depth_video.mp4\n",
      "\\n✅ SUCCESS! Video processing completed successfully!\n",
      "Input video: input_video.mp4\n",
      "Output video: output_depth_video.mp4\n",
      "\\nThe output video contains depth maps where:\n",
      "- Closer objects appear in warm colors (red, orange, yellow)\n",
      "- Farther objects appear in cool colors (blue, purple)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION CELL\n",
    "# Run this cell to process the video\n",
    "\n",
    "# Step 1: Display video information\n",
    "print(\"=== VIDEO PROCESSING PIPELINE ===\\\\n\")\n",
    "print(\"Step 1: Checking input video...\")\n",
    "display_video_info(INPUT_VIDEO_PATH)\n",
    "\n",
    "# Step 2: Optional - Test single frame (uncomment to test)\n",
    "# print(\"\\\\nStep 2: Testing single frame...\")\n",
    "# test_single_frame(INPUT_VIDEO_PATH, frame_number=0)\n",
    "\n",
    "# Step 3: Process the entire video\n",
    "print(\"\\\\nStep 3: Processing entire video...\")\n",
    "print(\"This may take a while depending on video length and hardware...\")\n",
    "success = process_video(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH, show_progress=True)\n",
    "\n",
    "if success:\n",
    "    print(\"\\\\n✅ SUCCESS! Video processing completed successfully!\")\n",
    "    print(f\"Input video: {INPUT_VIDEO_PATH}\")\n",
    "    print(f\"Output video: {OUTPUT_VIDEO_PATH}\")\n",
    "    print(\"\\\\nThe output video contains depth maps where:\")\n",
    "    print(\"- Closer objects appear in warm colors (red, orange, yellow)\")\n",
    "    print(\"- Farther objects appear in cool colors (blue, purple)\")\n",
    "else:\n",
    "    print(\"\\\\n❌ FAILED! Video processing encountered an error.\")\n",
    "    print(\"Please check the error messages above and ensure:\")\n",
    "    print(\"1. The input video file exists\")\n",
    "    print(\"2. The input video format is supported\")\n",
    "    print(\"3. You have sufficient disk space\")\n",
    "    print(\"4. All required packages are installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b575d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup and utility functions defined!\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP AND UTILITIES\n",
    "\n",
    "def cleanup_temp_files():\n",
    "    \"\"\"\n",
    "    Clean up temporary files and directories\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    if os.path.exists(TEMP_FRAMES_DIR):\n",
    "        shutil.rmtree(TEMP_FRAMES_DIR)\n",
    "        print(f\"Removed temporary directory: {TEMP_FRAMES_DIR}\")\n",
    "    else:\n",
    "        print(\"No temporary files to clean up.\")\n",
    "\n",
    "def batch_process_videos(video_list, output_prefix=\"depth_\"):\n",
    "    \"\"\"\n",
    "    Process multiple videos in batch\n",
    "    \n",
    "    Args:\n",
    "        video_list: List of video file paths\n",
    "        output_prefix: Prefix for output files\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, video_path in enumerate(video_list):\n",
    "        print(f\"\\\\n=== Processing video {i+1}/{len(video_list)}: {video_path} ===\")\n",
    "        \n",
    "        # Generate output filename\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        output_path = f\"{output_prefix}{video_name}.mp4\"\n",
    "        \n",
    "        # Process video\n",
    "        success = process_video(video_path, output_path)\n",
    "        results.append((video_path, output_path, success))\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\\\n=== BATCH PROCESSING SUMMARY ===\")\n",
    "    for video_path, output_path, success in results:\n",
    "        status = \"✅ SUCCESS\" if success else \"❌ FAILED\"\n",
    "        print(f\"{status}: {video_path} -> {output_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Optional: Clean up temporary files\n",
    "# cleanup_temp_files()\n",
    "\n",
    "print(\"Cleanup and utility functions defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704da76",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Depth Anything V2 Video Processing - Documentation\n",
    "\n",
    "## Overview\n",
    "This notebook processes video files to generate depth map visualizations using the Depth-Anything-V2 model. The output video shows depth information where warm colors (red, orange, yellow) represent closer objects and cool colors (blue, purple) represent farther objects.\n",
    "\n",
    "## Key Features\n",
    "- **Video Processing**: Processes entire video files frame by frame\n",
    "- **Depth Estimation**: Uses Depth-Anything-V2-Small-hf model for accurate depth estimation\n",
    "- **Colorized Output**: Converts depth maps to intuitive color representations\n",
    "- **Progress Tracking**: Shows processing progress with tqdm progress bars\n",
    "- **Batch Processing**: Support for processing multiple videos\n",
    "- **Error Handling**: Comprehensive error handling and informative messages\n",
    "\n",
    "## Required Dependencies\n",
    "```bash\n",
    "pip install torch transformers opencv-python matplotlib tqdm pillow\n",
    "```\n",
    "\n",
    "## Usage Steps\n",
    "1. **Install Dependencies**: Run the installation commands in cell 2\n",
    "2. **Configure Paths**: Modify `INPUT_VIDEO_PATH` and `OUTPUT_VIDEO_PATH` in cell 2\n",
    "3. **Run Processing**: Execute the main execution cell (cell 6)\n",
    "4. **Optional Testing**: Uncomment the single frame test to preview results\n",
    "\n",
    "## Technical Implementation\n",
    "\n",
    "### Core Components\n",
    "- **`process_frame()`**: Processes individual frames using the depth estimation pipeline\n",
    "- **`depth_to_colormap()`**: Converts depth maps to colorized visualizations using matplotlib's plasma colormap\n",
    "- **`process_video()`**: Main function that handles the complete video processing pipeline\n",
    "- **`get_video_properties()`**: Extracts video metadata (resolution, fps, frame count)\n",
    "\n",
    "### Processing Pipeline\n",
    "1. Load video and extract properties\n",
    "2. Initialize depth estimation model\n",
    "3. Process each frame:\n",
    "   - Convert BGR to RGB for PIL compatibility\n",
    "   - Generate depth map using Depth-Anything-V2\n",
    "   - Convert depth map to colorized representation\n",
    "   - Write processed frame to output video\n",
    "4. Save final video with original fps and resolution\n",
    "\n",
    "### Performance Considerations\n",
    "- Uses GPU acceleration if available (CUDA)\n",
    "- Processes videos frame by frame to manage memory usage\n",
    "- Progress tracking for long videos\n",
    "- Temporary file cleanup utilities\n",
    "\n",
    "## Output Format\n",
    "- **File Format**: MP4 video\n",
    "- **Resolution**: Same as input video\n",
    "- **Frame Rate**: Same as input video\n",
    "- **Color Scheme**: Plasma colormap (purple = far, yellow = close)\n",
    "\n",
    "## Troubleshooting\n",
    "- Ensure input video exists and is in a supported format\n",
    "- Check that all dependencies are installed\n",
    "- Verify sufficient disk space for output video\n",
    "- For large videos, ensure adequate RAM/VRAM\n",
    "\n",
    "## Advanced Usage\n",
    "- **Batch Processing**: Use `batch_process_videos()` for multiple files\n",
    "- **Custom Colormaps**: Modify `depth_to_colormap()` to use different color schemes\n",
    "- **Frame Testing**: Use `test_single_frame()` to preview results before full processing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
